{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import List,Iterator,Tuple\n",
    "from pyspark.sql.pandas.functions import pandas_udf\n",
    "from pyspark.sql.functions import struct, col\n",
    "\n",
    "from pyspark.sql.types import StringType,DoubleType\n",
    "from sparkstudy.deploy.demo_sessions import DemoSQLSessionFactory\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "COLUMNS = [\"name\",\"age\",\"salary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "比较下开不开启arrow的区别\n",
    "\n",
    "测试下来，感觉性能提升有点奇怪。有时候会快，有时候会慢。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def create_random_data(row_num:int)->List[tuple]:\n",
    "     result = list()\n",
    "     a_str = string.ascii_uppercase\n",
    "     for i in range(row_num):\n",
    "         random_letter = random.choice(a_str)\n",
    "         result.append((random_letter,random.randint(1,row_num),random.random()))\n",
    "     return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def test_performance(session_factory:DemoSQLSessionFactory, n:int = 100000):\n",
    "    data = create_random_data(n)\n",
    "    spark_session = session_factory.build_session()\n",
    "    df = spark_session.createDataFrame(data,COLUMNS).cache()\n",
    "    df.toPandas().head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.17 s, sys: 57.3 ms, total: 3.23 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "session_factory_normal = DemoSQLSessionFactory(name=\"normal\")\n",
    "%time test_performance(session_factory_normal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.64 s, sys: 20.7 ms, total: 2.66 s\n",
      "Wall time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "session_factory_arrow = DemoSQLSessionFactory(name=\"with arraw\")\n",
    "session_factory_arrow.add_config(\"spark.sql.execution.arrow.pyspark.enabled\",\"true\")\n",
    "%time test_performance(session_factory_arrow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "常规的HelloWorld的example。\n",
    "页面上面的第一个例子。本质就是生成一个新的dataframe\n",
    "1. 在annotation上面列出的是新的dataframe的col和类型\n",
    "2. 他会自动的把pd的转换成spark的\n",
    "3. 函数应该会分批node执行。然后再汇总。因为我看到了。hello world的函数会被执行好几次"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-------------------+\n",
      "|name| age|             salary|\n",
      "+----+----+-------------------+\n",
      "|   X| 981| 0.7073095672945235|\n",
      "|   Q| 902|0.09765986318709052|\n",
      "|   V|  10| 0.3852364010725843|\n",
      "|   B| 558|0.49268180032026987|\n",
      "|   E| 960|0.15956741825769705|\n",
      "|   T| 347|  0.134229798131681|\n",
      "|   U|  94|0.20868403846792571|\n",
      "|   E| 102| 0.5278589754699419|\n",
      "|   I| 398| 0.9390961853964784|\n",
      "|   Z| 787| 0.2688598344579807|\n",
      "|   H| 552| 0.4164119910611638|\n",
      "|   F| 936| 0.9507560150943194|\n",
      "|   X| 574| 0.6550968641233801|\n",
      "|   B| 377| 0.8364295345267588|\n",
      "|   C|1000| 0.8048297391977565|\n",
      "|   U| 593|0.39202752999800294|\n",
      "|   V| 489| 0.7930708888138559|\n",
      "|   W| 297|  0.904389303455135|\n",
      "|   R| 926|  0.589543682410987|\n",
      "|   G|  70| 0.5786476288393697|\n",
      "+----+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_factory_arrow.add_config('spark.sql.execution.arrow.maxRecordsPerBatch',10)\n",
    "spark = session_factory_arrow.build_session()\n",
    "test_data = create_random_data(row_num=1000)\n",
    "basic_df = spark.createDataFrame(test_data,COLUMNS)\n",
    "basic_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              result|\n",
      "+--------------------+\n",
      "| [981.7073095672945]|\n",
      "| [902.0976598631871]|\n",
      "|[10.385236401072584]|\n",
      "| [558.4926818003203]|\n",
      "| [960.1595674182577]|\n",
      "| [347.1342297981317]|\n",
      "| [94.20868403846792]|\n",
      "|[102.52785897546994]|\n",
      "|[398.93909618539647]|\n",
      "|  [787.268859834458]|\n",
      "| [552.4164119910612]|\n",
      "| [936.9507560150943]|\n",
      "| [574.6550968641234]|\n",
      "|[377.83642953452676]|\n",
      "|[1000.8048297391978]|\n",
      "|  [593.392027529998]|\n",
      "| [489.7930708888139]|\n",
      "|[297.90438930345516]|\n",
      "|  [926.589543682411]|\n",
      "| [70.57864762883936]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"total double\")\n",
    "def func(s1: pd.Series, s2: pd.Series) -> pd.DataFrame:\n",
    "    print(\"execute\")\n",
    "    s3 = pd.DataFrame()\n",
    "    s3['total'] = s1 + s2\n",
    "    return s3\n",
    "basic_df.select(func(\"age\",\"salary\").alias(\"result\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "主要是想要看看。select方法，不能不能接受一个List"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "| age|             salary|\n",
      "+----+-------------------+\n",
      "| 981| 0.7073095672945235|\n",
      "| 902|0.09765986318709052|\n",
      "|  10| 0.3852364010725843|\n",
      "| 558|0.49268180032026987|\n",
      "| 960|0.15956741825769705|\n",
      "| 347|  0.134229798131681|\n",
      "|  94|0.20868403846792571|\n",
      "| 102| 0.5278589754699419|\n",
      "| 398| 0.9390961853964784|\n",
      "| 787| 0.2688598344579807|\n",
      "| 552| 0.4164119910611638|\n",
      "| 936| 0.9507560150943194|\n",
      "| 574| 0.6550968641233801|\n",
      "| 377| 0.8364295345267588|\n",
      "|1000| 0.8048297391977565|\n",
      "| 593|0.39202752999800294|\n",
      "| 489| 0.7930708888138559|\n",
      "| 297|  0.904389303455135|\n",
      "| 926|  0.589543682410987|\n",
      "|  70| 0.5786476288393697|\n",
      "+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def to_str_func(s1: pd.Series) -> pd.Series:\n",
    "    return s1.astype(dtype=str)\n",
    "to_str = pandas_udf(to_str_func, returnType=StringType())\n",
    "\n",
    "age_c = to_str(\"age\").alias(\"age\")\n",
    "salary_c = to_str(\"salary\").alias(\"salary\")\n",
    "selects = [age_c,salary_c]\n",
    "basic_df.select(selects).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试以下。如果参数是不定的行不行\n",
    "\n",
    "简单的来书，\n",
    "- 确定的column个数，用Series\n",
    "- 不确定用dataframe\n",
    "- iterator是类似用流"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|            result|\n",
      "+------------------+\n",
      "| 693.8706855159276|\n",
      "| 88.08919659475565|\n",
      "| 3.852364010725843|\n",
      "| 274.9164445787106|\n",
      "|153.18472152738917|\n",
      "| 46.57773995169331|\n",
      "|19.616299615985017|\n",
      "| 53.84161549793407|\n",
      "| 373.7602817877984|\n",
      "| 211.5926897184308|\n",
      "| 229.8594190657624|\n",
      "| 889.9076301282829|\n",
      "| 376.0256000068202|\n",
      "| 315.3339345165881|\n",
      "| 804.8297391977565|\n",
      "|232.47232528881574|\n",
      "|387.81166462997555|\n",
      "| 268.6036231261751|\n",
      "| 545.9174499125739|\n",
      "| 40.50533401875588|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"double\")\n",
    "def to_sum_func(data: pd.DataFrame) -> pd.Series:\n",
    "    return data.age*data.salary\n",
    "cols = [col(\"age\"),col(\"salary\")]\n",
    "headers = struct(cols)\n",
    "#my_sum = pandas_udf(to_sum_func, returnType=DoubleType())\n",
    "basic_df.select(to_sum_func(headers).alias(\"result\")).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "能不能用于SQL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|pandas_to_str(age)|\n",
      "+------------------+\n",
      "|               981|\n",
      "|               902|\n",
      "|                10|\n",
      "|               558|\n",
      "|               960|\n",
      "|               347|\n",
      "|                94|\n",
      "|               102|\n",
      "|               398|\n",
      "|               787|\n",
      "|               552|\n",
      "|               936|\n",
      "|               574|\n",
      "|               377|\n",
      "|              1000|\n",
      "|               593|\n",
      "|               489|\n",
      "|               297|\n",
      "|               926|\n",
      "|                70|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "basic_df.createOrReplaceTempView(\"pandas_udf\")\n",
    "spark.udf.register(\"pandas_to_str\", to_str)\n",
    "spark.sql(\"select pandas_to_str(age) from pandas_udf\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "basic_df.createOrReplaceTempView(\"pandas_udf\")\n",
    "spark.udf.register(\"pandas_to_str\", to_str)\n",
    "spark.sql(\"select pandas_to_str(age) from pandas_udf\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`__call__`这个方法能不能用哪用"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|            result|\n",
      "+------------------+\n",
      "| 693.8706855159276|\n",
      "| 88.08919659475565|\n",
      "| 3.852364010725843|\n",
      "| 274.9164445787106|\n",
      "|153.18472152738917|\n",
      "| 46.57773995169331|\n",
      "|19.616299615985017|\n",
      "| 53.84161549793407|\n",
      "| 373.7602817877984|\n",
      "| 211.5926897184308|\n",
      "| 229.8594190657624|\n",
      "| 889.9076301282829|\n",
      "| 376.0256000068202|\n",
      "| 315.3339345165881|\n",
      "| 804.8297391977565|\n",
      "|232.47232528881574|\n",
      "|387.81166462997555|\n",
      "| 268.6036231261751|\n",
      "| 545.9174499125739|\n",
      "| 40.50533401875588|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class PandasFunc:\n",
    "    def __call__(self, data: pd.DataFrame)-> pd.Series:\n",
    "         return data.age*data.salary\n",
    "\n",
    "cols = [col(\"age\"),col(\"salary\")]\n",
    "headers = struct(cols)\n",
    "class_my_sum = pandas_udf(PandasFunc(), returnType=DoubleType())\n",
    "basic_df.select(class_my_sum(headers).alias(\"result\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}