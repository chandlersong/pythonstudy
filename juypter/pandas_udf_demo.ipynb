{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import struct, col\n",
    "from pyspark.sql.pandas.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "\n",
    "from sparkstudy.deploy.demo_sessions import DemoSQLSessionFactory\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "COLUMNS = [\"name\",\"age\",\"salary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "比较下开不开启arrow的区别\n",
    "\n",
    "测试下来，感觉性能提升有点奇怪。有时候会快，有时候会慢。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def create_random_data(row_num:int)->List[tuple]:\n",
    "     result = list()\n",
    "     a_str = string.ascii_uppercase\n",
    "     for i in range(row_num):\n",
    "         random_letter = random.choice(a_str)\n",
    "         result.append((random_letter,random.randint(1,row_num),random.random()))\n",
    "     return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def test_performance(session_factory:DemoSQLSessionFactory, n:int = 100000):\n",
    "    data = create_random_data(n)\n",
    "    spark_session = session_factory.build_session()\n",
    "    df = spark_session.createDataFrame(data,COLUMNS).cache()\n",
    "    df.toPandas().head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 54.4 ms, total: 2.8 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "session_factory_normal = DemoSQLSessionFactory(name=\"normal\")\n",
    "%time test_performance(session_factory_normal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.84 s, sys: 29.3 ms, total: 2.87 s\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "session_factory_arrow = DemoSQLSessionFactory(name=\"with arraw\")\n",
    "session_factory_arrow.add_config(\"spark.sql.execution.arrow.pyspark.enabled\",\"true\")\n",
    "%time test_performance(session_factory_arrow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "常规的HelloWorld的example。\n",
    "页面上面的第一个例子。本质就是生成一个新的dataframe\n",
    "1. 在annotation上面列出的是新的dataframe的col和类型\n",
    "2. 他会自动的把pd的转换成spark的\n",
    "3. 函数应该会分批node执行。然后再汇总。因为我看到了。hello world的函数会被执行好几次"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------------------+\n",
      "|name|age|              salary|\n",
      "+----+---+--------------------+\n",
      "|   V|998|  0.2713079265456966|\n",
      "|   W|473| 0.09608969362120778|\n",
      "|   F|678| 0.07191766994148774|\n",
      "|   M|624|  0.7805802879792632|\n",
      "|   S|361|  0.8922136333483364|\n",
      "|   G|505|  0.9017783167361239|\n",
      "|   C|389| 0.27793918129778183|\n",
      "|   M|247|  0.9734607293830692|\n",
      "|   X|874|  0.9584370599441783|\n",
      "|   F|384| 0.21520652529231066|\n",
      "|   V|699| 0.03320378604414065|\n",
      "|   I|764|  0.5951774351126187|\n",
      "|   H|597| 0.28892018066268255|\n",
      "|   N|985|  0.8533399451400041|\n",
      "|   F|459|  0.9953521916101892|\n",
      "|   P|316|  0.8110962722359051|\n",
      "|   J|206| 0.43682929686694527|\n",
      "|   X|850|   0.955839790517653|\n",
      "|   I|205| 0.46154739932642985|\n",
      "|   C|233|0.044360600720149246|\n",
      "+----+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_factory_arrow.add_config('spark.sql.execution.arrow.maxRecordsPerBatch',10)\n",
    "spark = session_factory_arrow.build_session()\n",
    "test_data = create_random_data(row_num=1000)\n",
    "basic_df = spark.createDataFrame(test_data,COLUMNS)\n",
    "basic_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              result|\n",
      "+--------------------+\n",
      "| [998.2713079265457]|\n",
      "| [473.0960896936212]|\n",
      "| [678.0719176699415]|\n",
      "| [624.7805802879793]|\n",
      "| [361.8922136333483]|\n",
      "| [505.9017783167361]|\n",
      "|[389.27793918129777]|\n",
      "|[247.97346072938308]|\n",
      "| [874.9584370599442]|\n",
      "|[384.21520652529233]|\n",
      "| [699.0332037860442]|\n",
      "| [764.5951774351126]|\n",
      "| [597.2889201806627]|\n",
      "|   [985.85333994514]|\n",
      "| [459.9953521916102]|\n",
      "| [316.8110962722359]|\n",
      "|[206.43682929686693]|\n",
      "| [850.9558397905176]|\n",
      "|[205.46154739932643]|\n",
      "|[233.04436060072015]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"total double\")\n",
    "def func(s1: pd.Series, s2: pd.Series) -> pd.DataFrame:\n",
    "    print(\"execute\")\n",
    "    s3 = pd.DataFrame()\n",
    "    s3['total'] = s1 + s2\n",
    "    return s3\n",
    "basic_df.select(func(\"age\",\"salary\").alias(\"result\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "主要是想要看看。select方法，不能不能接受一个List"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|age|              salary|\n",
      "+---+--------------------+\n",
      "|998|  0.2713079265456966|\n",
      "|473| 0.09608969362120778|\n",
      "|678| 0.07191766994148774|\n",
      "|624|  0.7805802879792632|\n",
      "|361|  0.8922136333483364|\n",
      "|505|  0.9017783167361239|\n",
      "|389| 0.27793918129778183|\n",
      "|247|  0.9734607293830692|\n",
      "|874|  0.9584370599441783|\n",
      "|384| 0.21520652529231066|\n",
      "|699| 0.03320378604414065|\n",
      "|764|  0.5951774351126187|\n",
      "|597| 0.28892018066268255|\n",
      "|985|  0.8533399451400041|\n",
      "|459|  0.9953521916101892|\n",
      "|316|  0.8110962722359051|\n",
      "|206| 0.43682929686694527|\n",
      "|850|   0.955839790517653|\n",
      "|205| 0.46154739932642985|\n",
      "|233|0.044360600720149246|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def to_str_func(s1: pd.Series) -> pd.Series:\n",
    "    return s1.astype(dtype=str)\n",
    "to_str = pandas_udf(to_str_func, returnType=StringType())\n",
    "\n",
    "age_c = to_str(\"age\").alias(\"age\")\n",
    "salary_c = to_str(\"salary\").alias(\"salary\")\n",
    "selects = [age_c,salary_c]\n",
    "basic_df.select(selects).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试以下。如果参数是不定的行不行\n",
    "\n",
    "简单的来书，\n",
    "- 确定的column个数，用Series\n",
    "- 不确定用dataframe\n",
    "- iterator是类似用流"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|            result|\n",
      "+------------------+\n",
      "|270.76531069260517|\n",
      "| 45.45042508283128|\n",
      "|48.760180220328685|\n",
      "| 487.0820996990602|\n",
      "| 322.0891216387494|\n",
      "|455.39804995174256|\n",
      "|108.11834152483713|\n",
      "| 240.4448001576181|\n",
      "| 837.6739903912118|\n",
      "| 82.63930571224729|\n",
      "|23.209446444854315|\n",
      "|454.71556042604067|\n",
      "|172.48534785562148|\n",
      "|  840.539845962904|\n",
      "|456.86665594907686|\n",
      "|  256.306422026546|\n",
      "| 89.98683515459072|\n",
      "|  812.463821940005|\n",
      "| 94.61721686191812|\n",
      "|10.336019967794774|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"double\")\n",
    "def to_sum_func(data: pd.DataFrame) -> pd.Series:\n",
    "    return data.age*data.salary\n",
    "cols = [col(\"age\"),col(\"salary\")]\n",
    "headers = struct(cols)\n",
    "#my_sum = pandas_udf(to_sum_func, returnType=DoubleType())\n",
    "basic_df.select(to_sum_func(headers).alias(\"result\")).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "能不能用于SQL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|pandas_to_str(age)|\n",
      "+------------------+\n",
      "|               998|\n",
      "|               473|\n",
      "|               678|\n",
      "|               624|\n",
      "|               361|\n",
      "|               505|\n",
      "|               389|\n",
      "|               247|\n",
      "|               874|\n",
      "|               384|\n",
      "|               699|\n",
      "|               764|\n",
      "|               597|\n",
      "|               985|\n",
      "|               459|\n",
      "|               316|\n",
      "|               206|\n",
      "|               850|\n",
      "|               205|\n",
      "|               233|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "basic_df.createOrReplaceTempView(\"pandas_udf\")\n",
    "spark.udf.register(\"pandas_to_str\", to_str)\n",
    "spark.sql(\"select pandas_to_str(age) from pandas_udf\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "basic_df.createOrReplaceTempView(\"pandas_udf\")\n",
    "spark.udf.register(\"pandas_to_str\", to_str)\n",
    "spark.sql(\"select pandas_to_str(age) from pandas_udf\").show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`__call__`这个方法能不能用哪用"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|            result|\n",
      "+------------------+\n",
      "|270.76531069260517|\n",
      "| 45.45042508283128|\n",
      "|48.760180220328685|\n",
      "| 487.0820996990602|\n",
      "| 322.0891216387494|\n",
      "|455.39804995174256|\n",
      "|108.11834152483713|\n",
      "| 240.4448001576181|\n",
      "| 837.6739903912118|\n",
      "| 82.63930571224729|\n",
      "|23.209446444854315|\n",
      "|454.71556042604067|\n",
      "|172.48534785562148|\n",
      "|  840.539845962904|\n",
      "|456.86665594907686|\n",
      "|  256.306422026546|\n",
      "| 89.98683515459072|\n",
      "|  812.463821940005|\n",
      "| 94.61721686191812|\n",
      "|10.336019967794774|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class PandasFunc:\n",
    "    def __call__(self, data: pd.DataFrame)-> pd.Series:\n",
    "         return data.age*data.salary\n",
    "\n",
    "cols = [col(\"age\"),col(\"salary\")]\n",
    "headers = struct(cols)\n",
    "class_my_sum = pandas_udf(PandasFunc(), returnType=DoubleType())\n",
    "basic_df.select(class_my_sum(headers).alias(\"result\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "返回多列的处理方法。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+--------------------+\n",
      "|age|              salary| col1|                col2|\n",
      "+---+--------------------+-----+--------------------+\n",
      "|998|  0.2713079265456966|998.0|  0.2713079265456966|\n",
      "|473| 0.09608969362120778|473.0| 0.09608969362120778|\n",
      "|678| 0.07191766994148774|678.0| 0.07191766994148774|\n",
      "|624|  0.7805802879792632|624.0|  0.7805802879792632|\n",
      "|361|  0.8922136333483364|361.0|  0.8922136333483364|\n",
      "|505|  0.9017783167361239|505.0|  0.9017783167361239|\n",
      "|389| 0.27793918129778183|389.0| 0.27793918129778183|\n",
      "|247|  0.9734607293830692|247.0|  0.9734607293830692|\n",
      "|874|  0.9584370599441783|874.0|  0.9584370599441783|\n",
      "|384| 0.21520652529231066|384.0| 0.21520652529231066|\n",
      "|699| 0.03320378604414065|699.0| 0.03320378604414065|\n",
      "|764|  0.5951774351126187|764.0|  0.5951774351126187|\n",
      "|597| 0.28892018066268255|597.0| 0.28892018066268255|\n",
      "|985|  0.8533399451400041|985.0|  0.8533399451400041|\n",
      "|459|  0.9953521916101892|459.0|  0.9953521916101892|\n",
      "|316|  0.8110962722359051|316.0|  0.8110962722359051|\n",
      "|206| 0.43682929686694527|206.0| 0.43682929686694527|\n",
      "|850|   0.955839790517653|850.0|   0.955839790517653|\n",
      "|205| 0.46154739932642985|205.0| 0.46154739932642985|\n",
      "|233|0.044360600720149246|233.0|0.044360600720149246|\n",
      "+---+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"col1 double, col2 double\")\n",
    "def to_multi_return_func(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"execute\")\n",
    "    s3 = pd.DataFrame()\n",
    "    s3['col1'] = data.age\n",
    "    s3['col2'] = data.salary\n",
    "    return s3\n",
    "cols = [col(\"age\"),col(\"salary\")]\n",
    "headers = struct(cols)\n",
    "#my_sum = pandas_udf(to_sum_func, returnType=DoubleType())\n",
    "multi_return_df = basic_df.withColumn(\"abc\",to_multi_return_func(headers))\n",
    "multi_return_df.select(col(\"age\"),col(\"salary\"),col(\"abc.col1\"),col(\"abc.col2\")).show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}