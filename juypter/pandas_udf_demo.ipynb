{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from pyspark.sql.pandas.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "from sparkstudy.deploy.demo_sessions import DemoSQLSessionFactory\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "COLUMNS = [\"name\",\"age\",\"salary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "比较下开不开启arrow的区别\n",
    "\n",
    "测试下来，感觉性能提升有点奇怪。有时候会快，有时候会慢。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def create_random_data(row_num:int)->List[tuple]:\n",
    "     result = list()\n",
    "     a_str = string.ascii_uppercase\n",
    "     for i in range(row_num):\n",
    "         random_letter = random.choice(a_str)\n",
    "         result.append((random_letter,random.randint(1,row_num),random.random()))\n",
    "     return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def test_performance(session_factory:DemoSQLSessionFactory, n:int = 100000):\n",
    "    data = create_random_data(n)\n",
    "    spark_session = session_factory.build_session()\n",
    "    df = spark_session.createDataFrame(data,COLUMNS).cache()\n",
    "    df.toPandas().head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.18 s, sys: 55.7 ms, total: 3.24 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "session_factory_normal = DemoSQLSessionFactory(name=\"normal\")\n",
    "%time test_performance(session_factory_normal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.68 s, sys: 17.6 ms, total: 2.7 s\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "session_factory_arrow = DemoSQLSessionFactory(name=\"with arraw\")\n",
    "session_factory_arrow.add_config(\"spark.sql.execution.arrow.pyspark.enabled\",\"true\")\n",
    "%time test_performance(session_factory_arrow)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "常规的HelloWorld的example。\n",
    "页面上面的第一个例子。本质就是生成一个新的dataframe\n",
    "1. 在annotation上面列出的是新的dataframe的col和类型\n",
    "2. 他会自动的把pd的转换成spark的\n",
    "3. 函数应该会分批node执行。然后再汇总。因为我看到了。hello world的函数会被执行好几次"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+--------------------+\n",
      "|name|age|              salary|\n",
      "+----+---+--------------------+\n",
      "|   F|707|   0.812187771740766|\n",
      "|   B|218|  0.7314196048714136|\n",
      "|   D|121|  0.7969774110261034|\n",
      "|   Z|167|  0.6048949931181556|\n",
      "|   I|231|  0.4425588872893208|\n",
      "|   F|923|   0.786461040523636|\n",
      "|   E|224|  0.6008017258769238|\n",
      "|   H|861|  0.3985002777129232|\n",
      "|   K|265|  0.5868977369408303|\n",
      "|   S|515|  0.6998075213477662|\n",
      "|   U|991|  0.8532631844261254|\n",
      "|   K| 62| 0.06972587357982074|\n",
      "|   A|675|   0.771642388640452|\n",
      "|   C|208|  0.6162263414662013|\n",
      "|   R|172|  0.7694505306855899|\n",
      "|   H|209| 0.24354272924336706|\n",
      "|   K|213|0.015653818926125607|\n",
      "|   H|156|  0.5330514618813238|\n",
      "|   B|748|  0.8394659136558289|\n",
      "|   P|581|    0.88864851447575|\n",
      "+----+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "session_factory_arrow.add_config('spark.sql.execution.arrow.maxRecordsPerBatch',10)\n",
    "spark = session_factory_arrow.build_session()\n",
    "test_data = create_random_data(row_num=1000)\n",
    "basic_df = spark.createDataFrame(test_data,COLUMNS)\n",
    "basic_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              result|\n",
      "+--------------------+\n",
      "| [707.8121877717408]|\n",
      "| [218.7314196048714]|\n",
      "| [121.7969774110261]|\n",
      "|[167.60489499311817]|\n",
      "|[231.44255888728932]|\n",
      "| [923.7864610405236]|\n",
      "|[224.60080172587692]|\n",
      "|  [861.398500277713]|\n",
      "|[265.58689773694084]|\n",
      "| [515.6998075213478]|\n",
      "| [991.8532631844262]|\n",
      "| [62.06972587357982]|\n",
      "| [675.7716423886404]|\n",
      "| [208.6162263414662]|\n",
      "| [172.7694505306856]|\n",
      "|[209.24354272924336]|\n",
      "|[213.01565381892613]|\n",
      "| [156.5330514618813]|\n",
      "| [748.8394659136559]|\n",
      "| [581.8886485144758]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(\"total double\")\n",
    "def func(s1: pd.Series, s2: pd.Series) -> pd.DataFrame:\n",
    "    print(\"execute\")\n",
    "    s3 = pd.DataFrame()\n",
    "    s3['total'] = s1 + s2\n",
    "    return s3\n",
    "basic_df.select(func(\"age\",\"salary\").alias(\"result\")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "主要是想要看看。select方法，不能不能接受一个List"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|age|              salary|\n",
      "+---+--------------------+\n",
      "|707|   0.812187771740766|\n",
      "|218|  0.7314196048714136|\n",
      "|121|  0.7969774110261034|\n",
      "|167|  0.6048949931181556|\n",
      "|231|  0.4425588872893208|\n",
      "|923|   0.786461040523636|\n",
      "|224|  0.6008017258769238|\n",
      "|861|  0.3985002777129232|\n",
      "|265|  0.5868977369408303|\n",
      "|515|  0.6998075213477662|\n",
      "|991|  0.8532631844261254|\n",
      "| 62| 0.06972587357982074|\n",
      "|675|   0.771642388640452|\n",
      "|208|  0.6162263414662013|\n",
      "|172|  0.7694505306855899|\n",
      "|209| 0.24354272924336706|\n",
      "|213|0.015653818926125607|\n",
      "|156|  0.5330514618813238|\n",
      "|748|  0.8394659136558289|\n",
      "|581|    0.88864851447575|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def to_str_func(s1: pd.Series) -> pd.Series:\n",
    "    return s1.astype(dtype=str)\n",
    "to_str = pandas_udf(to_str_func, returnType=StringType())\n",
    "\n",
    "age_c = to_str(\"age\").alias(\"age\")\n",
    "salary_c = to_str(\"salary\").alias(\"salary\")\n",
    "selects = [age_c,salary_c]\n",
    "basic_df.select(selects).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}