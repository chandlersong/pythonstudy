{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, struct, collect_list\n",
    "from pyspark.sql.types import IntegerType\n",
    "from sparkstudy.deploy.demo_sessions import DemoSQLSessionFactory\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "舒适化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+\n",
      "|str_age|name|address|\n",
      "+-------+----+-------+\n",
      "|      1|   a|      e|\n",
      "|      2|   b|      f|\n",
      "|      3|   c|      g|\n",
      "+-------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sessionFactory = DemoSQLSessionFactory(name=\"local file\")\n",
    "spark = sessionFactory.build_session()\n",
    "data = [(\"1\",\"a\",\"e\"),(\"2\",\"b\",\"f\"),(\"3\",\"c\",\"g\")]\n",
    "columns = [\"str_age\",\"name\",\"address\"]\n",
    "logData = spark.createDataFrame(data, columns).cache()\n",
    "logData.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面这个例子。是一个读一列的例子。\n",
    "[例子来源](https://www.bmc.com/blogs/how-to-write-spark-udf-python/)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "colsInt = udf(lambda z: to_int(z), IntegerType())\n",
    "spark.udf.register(\"colsInt\", colsInt)\n",
    "def to_int(s):\n",
    "    if isinstance(s, str):\n",
    "        return int(s)\n",
    "    else:\n",
    "         return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+---+\n",
      "|str_age|name|address|age|\n",
      "+-------+----+-------+---+\n",
      "|      1|   a|      e|  1|\n",
      "|      2|   b|      f|  2|\n",
      "|      3|   c|      g|  3|\n",
      "+-------+----+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = logData.withColumn('age',colsInt('str_age'))\n",
    "df2.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "读多列的样子"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def count_columns(row):\n",
    "    for r in row:\n",
    "        print(r)\n",
    "    return len(row)\n",
    "countRow = udf(lambda row: count_columns(row), IntegerType())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+-------+\n",
      "|str_age|name|address|columns|\n",
      "+-------+----+-------+-------+\n",
      "|      1|   a|      e|      2|\n",
      "|      2|   b|      f|      2|\n",
      "|      3|   c|      g|      2|\n",
      "+-------+----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = struct('name','address')\n",
    "df3 = logData.withColumn(\"columns\", countRow(columns))\n",
    "df3.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "作用于SQL 发觉需要做以下几件事情。\n",
    "1. 注册成为函数。\n",
    "2. 在SQL中使用\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "spark.udf.register(\"to_int\", to_int)\n",
    "\n",
    "\n",
    "\n",
    "logData.createOrReplaceTempView(\"logdata\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|abc|col_num|\n",
      "+---+-------+\n",
      "|  1|      3|\n",
      "|  2|      3|\n",
      "|  3|      3|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_sql_columns(*row):\n",
    "    for r in row:\n",
    "        print(r)\n",
    "    return len(row)\n",
    "spark.udf.register(\"count_sql_columns\", count_sql_columns)\n",
    "sql_data = spark.sql(\"select to_int(str_age) as abc, count_sql_columns(*) as col_num from logdata\")\n",
    "sql_data.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "聚合，简单的来收，就是groupby"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+\n",
      "|str_age|name|address|\n",
      "+-------+----+-------+\n",
      "|      1|   a|      e|\n",
      "|      2|   a|      e|\n",
      "|      3|   a|      e|\n",
      "|      4|   b|      f|\n",
      "|      3|   c|      g|\n",
      "+-------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "agg_data = [(\"1\",\"a\",\"e\"),\n",
    "            (\"2\",\"a\",\"e\"),\n",
    "            (\"3\",\"a\",\"e\"),\n",
    "            (\"4\",\"b\",\"f\"),\n",
    "            (\"3\",\"c\",\"g\")]\n",
    "columns = [\"str_age\",\"name\",\"address\"]\n",
    "agg_df = spark.createDataFrame(agg_data, columns).cache()\n",
    "agg_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|str_age|a_count|\n",
      "+-------+-------+\n",
      "|      3|      1|\n",
      "|      1|      1|\n",
      "|      4|      0|\n",
      "|      2|      1|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_a(x):\n",
    "  \"\"\"Count 'a's in list.\"\"\"\n",
    "  output_count = 0\n",
    "  print(x)\n",
    "  for i in x:\n",
    "    if i == 'a':\n",
    "      output_count += 1\n",
    "  return output_count\n",
    "\n",
    "find_a_udf = udf(find_a, IntegerType())\n",
    "agg_df.groupBy('str_age').\\\n",
    "       agg(find_a_udf(collect_list('name')).\n",
    "       alias('a_count')).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}